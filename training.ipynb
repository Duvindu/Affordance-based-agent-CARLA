{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8YSJ_MuKSRJN"
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "import pickle\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import optim\n",
    "import torch.nn as nn\n",
    "#from ipdb import set_trace\n",
    "from datetime import datetime\n",
    "import time\n",
    "import copy\n",
    "from util_funcs import *\n",
    "from tqdm import tqdm\n",
    "from ipdb import set_trace\n",
    "import argparse\n",
    "from torch.utils.data import Dataset\n",
    "from matplotlib import image\n",
    "from matplotlib import pyplot\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "#sys.path.insert(0, \"../prev_work/CAL/training\")\n",
    "\n",
    "#from train import fit, custom_loss, validate\n",
    "from metrics import calc_metrics\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "plt.ion()   # interactive mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dWSZYEt_1j-s"
   },
   "outputs": [],
   "source": [
    "def onehot(vals, possible_vals):\n",
    "    if not isinstance(possible_vals, list): raise TypeError(\"provide possible_vals as a list\")\n",
    "    enc_vals = np.zeros([len(vals), len(possible_vals)])\n",
    "    for i, value in enumerate(vals):\n",
    "        if isinstance(possible_vals[0], float):\n",
    "            enc = np.where(abs(possible_vals-value)<1e-3)\n",
    "        else:\n",
    "            enc = np.where(possible_vals==value)\n",
    "        enc_vals[i,enc] = 1\n",
    "    return enc_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I5kdFmDunl-3"
   },
   "outputs": [],
   "source": [
    "class Rescale(object):\n",
    "    def __init__(self, scalar):\n",
    "        self.scalar = scalar\n",
    "\n",
    "    def __call__(self, im):\n",
    "        w, h = [int(s*self.scalar) for s in im.size]\n",
    "        return transforms.Resize((h, w))(im)\n",
    "\n",
    "class Crop(object):\n",
    "    def __init__(self, box):\n",
    "        assert len(box) == 4\n",
    "        self.box = box\n",
    "\n",
    "    def __call__(self, im):\n",
    "        return im.crop(self.box)\n",
    "\n",
    "class Augment(object):\n",
    "    def __init__(self, seq):\n",
    "        self.seq = seq\n",
    "\n",
    "    def __call__(self, im):\n",
    "        return Image.fromarray(self.seq.augment_images([np.array(im)])[0])\n",
    "\n",
    "def get_data_transforms(t='train'):\n",
    "    data_transforms = {\n",
    "        'train': transforms.Compose([\n",
    "#             display_image(),\n",
    "            Crop((0,120,800,480)),\n",
    "            Rescale(0.4),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ]),\n",
    "        'val': transforms.Compose([\n",
    "            Crop((0,120,800,480)),\n",
    "            Rescale(0.4),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ]),\n",
    "    }\n",
    "    return data_transforms[t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YWlWnMvlY2is"
   },
   "outputs": [],
   "source": [
    "\n",
    "#LABEL_KEYS = ['v_throttle', 'v_break', 'v_steer', 'traffic_light', 'front_vehicle', 'centre_dist', 'pedestrian_distance']\n",
    "\n",
    "class CARLA_Dataset(Dataset):\n",
    "    def __init__(self, t, pickle_file_path_l, image_dir_path, pickle_file_path_r):\n",
    "        #self.inputs, self.labels = {}, {}\n",
    "        #initializing transforms\n",
    "        assert t in ['train', 'val']\n",
    "        self.transform = get_data_transforms(t)\n",
    "        self.labels = {}    \n",
    "        ###############LEFT CAMERA##############\n",
    "        #reading the title of all images to access the pickle file\n",
    "        self.image_path = image_dir_path\n",
    "        self.image_list = os.listdir(image_dir_path)\n",
    "        #self.image_list_l.remove('.DS_Store')\n",
    "        self.file_name = []\n",
    "        for file in self.image_list:\n",
    "            self.file_name.append(os.path.splitext(file)[0])\n",
    "            \n",
    "        #initialize the labels \n",
    "\n",
    "        \n",
    "        #read pickle file\n",
    "        self.pickle_list_l = os.listdir(pickle_file_path_l)\n",
    "        self.pickled_data_l = {}\n",
    "        for file in self.pickle_list_l:\n",
    "            f = open((pickle_file_path_l + file), 'rb')  \n",
    "            self.pickled_data_l.update(pickle.load(f))\n",
    "            f.close() \n",
    "        \n",
    "        ###############RIGHT CAMERA##############\n",
    "    \n",
    "        \n",
    "        #read pickle file\n",
    "        self.pickle_list_r = os.listdir(pickle_file_path_r)\n",
    "        self.pickled_data_r = {}\n",
    "        for file in self.pickle_list_r:\n",
    "            f = open((pickle_file_path_r + file), 'rb')  \n",
    "            self.pickled_data_r.update(pickle.load(f))\n",
    "            f.close() \n",
    "        \n",
    "        # transform reg affordances\n",
    "        #reg_keys = ['front_vehicle', 'centre_dist', 'pedestrian_distance']\n",
    "        #for key in self.pickled_data:\n",
    "        #   entry = self.pickled_data[key]\n",
    "            #print(\"1.\", entry['front_vehicle'])\n",
    "        #reg_norm = entry[reg_keys] / abs(entry[reg_keys]).max()\n",
    "                # transform cls affordances\n",
    "      \n",
    "        f.close() \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_name)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        frames      = []\n",
    "        inputs = {}\n",
    "            \n",
    "        #####################LEFT CAMERA################\n",
    "        #reading PIL\n",
    "        self.raw_image = Image.open(os.path.join(self.image_path, self.image_list[idx])).convert('RGB')\n",
    "        #pyplot.imshow(self.raw_image_l)\n",
    "        #pyplot.show()\n",
    "        \n",
    "        #reading file name to access the pickle file\n",
    "        current_fname = self.file_name[idx]\n",
    "        chk_camera = current_fname[-3:]\n",
    "\n",
    "        if chk_camera == '_rt' :\n",
    "            current_fname_r = current_fname[:-3]\n",
    "            label_dict = self.pickled_data_r[current_fname_r] \n",
    "\n",
    "        else :\n",
    "\n",
    "            label_dict = self.pickled_data_l[current_fname] \n",
    "            \n",
    "        label_values = list(label_dict.values())\n",
    "        \n",
    "        #transforming regression labels\n",
    "        self.labels['front_vehicle'] = torch.Tensor(np.array(float(label_dict['front_vehicle'])))\n",
    "        self.labels['centre_dist'] = torch.Tensor(np.array(float(label_dict['centre_dist'])))\n",
    "        self.labels['pedestrian_distance'] = torch.Tensor(np.array(float(label_dict['pedestrian_distance'])))\n",
    "        \n",
    "        #transforming classification labels\n",
    "        #self.labels_l['traffic_light'] = torch.Tensor(onehot(np.array(label_dict['traffic_light']), [False, 'Green', True, 'Red']))\n",
    "        #transforming raw PIL image\n",
    "        im = self.transform(self.raw_image)\n",
    "        \n",
    "        inputs ['sequence'] = im\n",
    "        \n",
    "        #print(inputs ['sequence'].dim())\n",
    "        return inputs, self.labels\n",
    "\n",
    "            \n",
    "        ###############RIGHT CAMERA####################\n",
    "        #reading PIL\n",
    "        #self.raw_image_r = Image.open(os.path.join(self.image_path_r, self.image_list_r[idx])).convert('RGB')\n",
    "        #pyplot.imshow(self.raw_image_r)\n",
    "        #pyplot.show()\n",
    "        \n",
    "        #reading file name to access the pickle file\n",
    "        #current_fname_r = self.file_name_r[idx]\n",
    "        #label_dict_r = self.pickled_data_r[current_fname_r]       \n",
    "        #label_values_r = list(label_dict_r.values())\n",
    "       \n",
    "        #transforming regression labels\n",
    "        #self.labels_r['front_vehicle'] = torch.Tensor(np.array(float(label_dict_r['front_vehicle'])))\n",
    "        #self.labels_r['centre_dist'] = torch.Tensor(np.array(float(label_dict_r['centre_dist'])))\n",
    "        #self.labels_r['pedestrian_distance'] = torch.Tensor(np.array(float(label_dict_r['pedestrian_distance'])))\n",
    "        \n",
    "        #transforming classification labels\n",
    "       # self.labels_r['traffic_light'] = torch.Tensor(onehot(np.array(label_dict_r['traffic_light']), [False, 'Green', True, 'Red']))\n",
    "        \n",
    "        #transforming raw PIL image\n",
    "       # im_r = self.transform(self.raw_image_r)\n",
    "        \n",
    "        #inputs ['sequence'] = im_r\n",
    "            \n",
    "        #return transformed image and labels\n",
    "        #sample = {'image_l' : im_l, 'labels_l' : self.labels_l ,'image_r' : im_r, 'labels_r' : self.labels_r}\n",
    "        #return sample\n",
    "\n",
    "        \n",
    "        #self.labels['v_break'] = torch.Tensor(onehot(np.array(list(label_dict['v_break'])), [0.0, 1.0]))\n",
    "        #print(label_dict['traffic_light'])\n",
    "        #print(self.labels['traffic_light'])\n",
    "        #print(label_dict['v_break'])\n",
    "        #print(self.labels['v_break'])\n",
    "        #pyplot.imshow(self.raw_image)\n",
    "        #pyplot.show()\n",
    "        #reg_keys = ('front_vehicle', 'centre_dist', 'pedestrian_distance', 'v_steer')\n",
    "        #reg_norm = label_dict[reg_keys] / abs(label_dict[reg_keys]).max()\n",
    "        #reg_norm = label_dict[reg_keys]\n",
    "\n",
    "        #for i in 'front_vehicle', 'centre_dist', 'pedestrian_distance', 'v_steer':\n",
    "        #  reg_norm = label_dict[i] / abs(label_dict[i])\n",
    "        #  print(i, reg_norm)\n",
    "        #print(type(reg_keys))\n",
    "        #reg_norm = label_dict['front_vehicle', 'centre_dist'] / max(abs(label_dict['front_vehicle', 'centre_dist']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 853
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1140,
     "status": "ok",
     "timestamp": 1572580450204,
     "user": {
      "displayName": "Seima Saki",
      "photoUrl": "",
      "userId": "02501578531897632617"
     },
     "user_tz": -480
    },
    "id": "pg-IJ8D-_x1S",
    "outputId": "657a685a-8200-44e4-d42f-6db08adee6eb"
   },
   "outputs": [],
   "source": [
    "#C_dataset = CARLA_Dataset( 'train', pickle_file_path_l='/Users/seimasaki/CE7454_2019/codes/data/Left_pickle_file/', image_dir_path='/Users/seimasaki/CE7454_2019/codes/data/Left_camera/', pickle_file_path_r='/Users/seimasaki/CE7454_2019/codes/data/Right_pickle_file/')\n",
    "\n",
    "#for i in range(len(C_dataset)):\n",
    "  #  sample = C_dataset[i]\n",
    "   # print(sample[0])\n",
    " #print(sample['labels_l'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(batch_size):\n",
    "    train_ds = CARLA_Dataset( 'train', pickle_file_path_l='Training_data/Left_pickle_file/',\n",
    "                                    image_dir_path='Training_data/Camera/', \n",
    "                                    pickle_file_path_r='Training_data/Right_pickle_file/')\n",
    "    val_ds = CARLA_Dataset( 'val', pickle_file_path_l='Training_data/Left_pickle_file/',\n",
    "                                    image_dir_path='Training_data/Camera/', \n",
    "                                    pickle_file_path_r='Training_data/Right_pickle_file/')\n",
    "    return (len(train_ds),len(val_ds),DataLoader(train_ds, batch_size=batch_size, shuffle=True, pin_memory=True, num_workers=10),\n",
    "        DataLoader(val_ds, batch_size=batch_size*2, pin_memory=True, num_workers=10),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(get_data(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##########################################################\n",
    "# pytorch util functions \n",
    "##########################################################\n",
    "\n",
    "def load_checkpoint(filename) :\n",
    "    #print(filename)\n",
    "    checkpoint = torch.load(filename)\n",
    "    model_state_dict = checkpoint['model_state_dict']\n",
    "    optimizer_state_dict = checkpoint['optimizer_state_dict']\n",
    "    epoch = checkpoint['epoch']\n",
    "    loss = checkpoint['loss']\n",
    "    return [model_state_dict, optimizer_state_dict, epoch, loss]\n",
    "\n",
    "def save_checkpoint(model, optimizer, epoch, loss, filename):\n",
    "    print(\"Saving Checkpoint....\")\n",
    "    model_state_dict = model.state_dict()\n",
    "    optimizer_state_dict = optimizer.state_dict()\n",
    "#     print(\"model_state_dict : \", model_state_dict)\n",
    "#     print(\"optimizer_state_dict : \", optimizer_state_dict)\n",
    "#     print(\"Epoch : \", epoch)\n",
    "#     print(\"filename : \", filename)\n",
    "\n",
    "    torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model_state_dict,\n",
    "            'optimizer_state_dict': optimizer_state_dict,\n",
    "            'loss': loss\n",
    "            }, filename)\n",
    "    print(\"Saving Checkpoint Done\")\n",
    "\n",
    "def display_image(image) : \n",
    "    plt.show(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_inputs(inputs_old, labels):\n",
    "    inputs            = inputs_old['sequence']\n",
    "    #print(\"labels keys : \", labels.keys())\n",
    "    #labels = list(sample['labels_l'].values())\n",
    "    labels_vdistance  = labels['front_vehicle']\n",
    "    labels_cdistance  = labels['centre_dist']\n",
    "    labels_direction  = labels['pedestrian_distance']\n",
    "    combined_label    = torch.stack([labels_vdistance, labels_cdistance, labels_direction], dim=1)\n",
    "    #print(\"combined_label shape : \", combined_label.size())\n",
    "    return inputs, combined_label\n",
    "    #return combined_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloaders, dataset_sizes, criterion, optimizer, scheduler, num_epochs=30):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    best_loss = 0.0\n",
    "    epoch_acc = 0.0\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            #for inputs, labels in dataloaders[phase]:\n",
    "            for i, data in enumerate(dataloaders[phase]) :\n",
    "            #for i, data in tqdm(dataloaders[phase]) :\n",
    "                inputs_old = data[0]\n",
    "                #print(\"input before convertion\", inputs_old)\n",
    "                labels = data[1]\n",
    "                inputs, labels = convert_inputs(inputs_old ,labels)\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    #_, preds = torch.max(outputs, 1)\n",
    "                    preds = outputs\n",
    "                    #print(outputs.size(), labels.size())\n",
    "                    #input(\"Enter\")\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                        if(i%100 == 0) :\n",
    "                            print(\"preds shape : \", preds.size(), \" labels shape : \", labels.size())\n",
    "                            print(\"preds : \", preds[0].T.data, \"\\nlabels : \", labels.data[0].T.data)\n",
    "                            print(\"loss :\", loss.item())\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                #running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "                if(phase == 'val') :\n",
    "                    if(i%10==0) :\n",
    "                        print(\"preds : \", preds[0].T.data, \"\\nlabels : \", labels.data[0].T.data)\n",
    "                        print(\"loss :\", loss.item())\n",
    "                #if(i==10) : \n",
    "                #    break\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            #epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            #if phase == 'val' and epoch_acc > best_acc:\n",
    "            if phase == 'val' and epoch_loss < best_loss:\n",
    "                #best_acc = epoch_acc\n",
    "                best_loss = epoch_loss\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            if phase == 'train'  :\n",
    "                checkpoint_name = 'checkpoints/model_' + str(epoch) + '.tar'\n",
    "                save_checkpoint(model, optimizer, epoch, epoch_loss, checkpoint_name)\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_checkpoint_weights(checkpoint, model) :\n",
    "    print(\"checkpoint name : \", checkpoint)\n",
    "    _model_state_dict, _optimizer_state_dict, _epoch, _loss = load_checkpoint(checkpoint)\n",
    "    model.load_state_dict(_model_state_dict)\n",
    "\n",
    "def resume_model(checkpoint, model, optimizer) : \n",
    "    print(\"checkpoint name : \", checkpoint)\n",
    "    _model_state_dict, _optimizer_state_dict, _epoch, _loss = load_checkpoint(checkpoint)\n",
    "    #print(_model_state_dict)\n",
    "    model.load_state_dict(_model_state_dict)\n",
    "    optimizer.load_state_dict(_optimizer_state_dict)\n",
    "    print(\"resume model succesful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11158\n",
      "11158\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7f3e8eb1e828>\n"
     ]
    }
   ],
   "source": [
    "len_train_ds, len_valid_ds, train_dl, valid_dl = get_data(batch_size=128)\n",
    "print(len_train_ds)\n",
    "print(len_valid_ds)\n",
    "\n",
    "dataloaders   = {'train':train_dl, 'val':valid_dl}\n",
    "print(dataloaders['train'])\n",
    "dataset_sizes = {'train':len_train_ds, 'val':len_valid_ds}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset sizes : {'train': 11158, 'val': 11158}\n"
     ]
    }
   ],
   "source": [
    "print(\"dataset sizes :\", dataset_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint name :  ../python/checkpoints/vehicle_distance/model_19.tar\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for ResNet:\n\tMissing key(s) in state_dict: \"conv1.weight\", \"bn1.bias\", \"bn1.weight\", \"bn1.running_mean\", \"bn1.running_var\", \"layer1.0.conv1.weight\", \"layer1.0.bn1.bias\", \"layer1.0.bn1.weight\", \"layer1.0.bn1.running_mean\", \"layer1.0.bn1.running_var\", \"layer1.0.conv2.weight\", \"layer1.0.bn2.bias\", \"layer1.0.bn2.weight\", \"layer1.0.bn2.running_mean\", \"layer1.0.bn2.running_var\", \"layer1.0.conv3.weight\", \"layer1.0.bn3.bias\", \"layer1.0.bn3.weight\", \"layer1.0.bn3.running_mean\", \"layer1.0.bn3.running_var\", \"layer1.0.downsample.0.weight\", \"layer1.0.downsample.1.bias\", \"layer1.0.downsample.1.weight\", \"layer1.0.downsample.1.running_mean\", \"layer1.0.downsample.1.running_var\", \"layer1.1.conv1.weight\", \"layer1.1.bn1.bias\", \"layer1.1.bn1.weight\", \"layer1.1.bn1.running_mean\", \"layer1.1.bn1.running_var\", \"layer1.1.conv2.weight\", \"layer1.1.bn2.bias\", \"layer1.1.bn2.weight\", \"layer1.1.bn2.running_mean\", \"layer1.1.bn2.running_var\", \"layer1.1.conv3.weight\", \"layer1.1.bn3.bias\", \"layer1.1.bn3.weight\", \"layer1.1.bn3.running_mean\", \"layer1.1.bn3.running_var\", \"layer1.2.conv1.weight\", \"layer1.2.bn1.bias\", \"layer1.2.bn1.weight\", \"layer1.2.bn1.running_mean\", \"layer1.2.bn1.running_var\", \"layer1.2.conv2.weight\", \"layer1.2.bn2.bias\", \"layer1.2.bn2.weight\", \"layer1.2.bn2.running_mean\", \"layer1.2.bn2.running_var\", \"layer1.2.conv3.weight\", \"layer1.2.bn3.bias\", \"layer1.2.bn3.weight\", \"layer1.2.bn3.running_mean\", \"layer1.2.bn3.running_var\", \"layer2.0.conv1.weight\", \"layer2.0.bn1.bias\", \"layer2.0.bn1.weight\", \"layer2.0.bn1.running_mean\", \"layer2.0.bn1.running_var\", \"layer2.0.conv2.weight\", \"layer2.0.bn2.bias\", \"layer2.0.bn2.weight\", \"layer2.0.bn2.running_mean\", \"layer2.0.bn2.running_var\", \"layer2.0.conv3.weight\", \"layer2.0.bn3.bias\", \"layer2.0.bn3.weight\", \"layer2.0.bn3.running_mean\", \"layer2.0.bn3.running_var\", \"layer2.0.downsample.0.weight\", \"layer2.0.downsample.1.bias\", \"layer2.0.downsample.1.weight\", \"layer2.0.downsample.1.running_mean\", \"layer2.0.downsample.1.running_var\", \"layer2.1.conv1.weight\", \"layer2.1.bn1.bias\", \"layer2.1.bn1.weight\", \"layer2.1.bn1.running_mean\", \"layer2.1.bn1.running_var\", \"layer2.1.conv2.weight\", \"layer2.1.bn2.bias\", \"layer2.1.bn2.weight\", \"layer2.1.bn2.running_mean\", \"layer2.1.bn2.running_var\", \"layer2.1.conv3.weight\", \"layer2.1.bn3.bias\", \"layer2.1.bn3.weight\", \"layer2.1.bn3.running_mean\", \"layer2.1.bn3.running_var\", \"layer2.2.conv1.weight\", \"layer2.2.bn1.bias\", \"layer2.2.bn1.weight\", \"layer2.2.bn1.running_mean\", \"layer2.2.bn1.running_var\", \"layer2.2.conv2.weight\", \"layer2.2.bn2.bias\", \"layer2.2.bn2.weight\", \"layer2.2.bn2.running_mean\", \"layer2.2.bn2.running_var\", \"layer2.2.conv3.weight\", \"layer2.2.bn3.bias\", \"layer2.2.bn3.weight\", \"layer2.2.bn3.running_mean\", \"layer2.2.bn3.running_var\", \"layer2.3.conv1.weight\", \"layer2.3.bn1.bias\", \"layer2.3.bn1.weight\", \"layer2.3.bn1.running_mean\", \"layer2.3.bn1.running_var\", \"layer2.3.conv2.weight\", \"layer2.3.bn2.bias\", \"layer2.3.bn2.weight\", \"layer2.3.bn2.running_mean\", \"layer2.3.bn2.running_var\", \"layer2.3.conv3.weight\", \"layer2.3.bn3.bias\", \"layer2.3.bn3.weight\", \"layer2.3.bn3.running_mean\", \"layer2.3.bn3.running_var\", \"layer3.0.conv1.weight\", \"layer3.0.bn1.bias\", \"layer3.0.bn1.weight\", \"layer3.0.bn1.running_mean\", \"layer3.0.bn1.running_var\", \"layer3.0.conv2.weight\", \"layer3.0.bn2.bias\", \"layer3.0.bn2.weight\", \"layer3.0.bn2.running_mean\", \"layer3.0.bn2.running_var\", \"layer3.0.conv3.weight\", \"layer3.0.bn3.bias\", \"layer3.0.bn3.weight\", \"layer3.0.bn3.running_mean\", \"layer3.0.bn3.running_var\", \"layer3.0.downsample.0.weight\", \"layer3.0.downsample.1.bias\", \"layer3.0.downsample.1.weight\", \"layer3.0.downsample.1.running_mean\", \"layer3.0.downsample.1.running_var\", \"layer3.1.conv1.weight\", \"layer3.1.bn1.bias\", \"layer3.1.bn1.weight\", \"layer3.1.bn1.running_mean\", \"layer3.1.bn1.running_var\", \"layer3.1.conv2.weight\", \"layer3.1.bn2.bias\", \"layer3.1.bn2.weight\", \"layer3.1.bn2.running_mean\", \"layer3.1.bn2.running_var\", \"layer3.1.conv3.weight\", \"layer3.1.bn3.bias\", \"layer3.1.bn3.weight\", \"layer3.1.bn3.running_mean\", \"layer3.1.bn3.running_var\", \"layer3.2.conv1.weight\", \"layer3.2.bn1.bias\", \"layer3.2.bn1.weight\", \"layer3.2.bn1.running_mean\", \"layer3.2.bn1.running_var\", \"layer3.2.conv2.weight\", \"layer3.2.bn2.bias\", \"layer3.2.bn2.weight\", \"layer3.2.bn2.running_mean\", \"layer3.2.bn2.running_var\", \"layer3.2.conv3.weight\", \"layer3.2.bn3.bias\", \"layer3.2.bn3.weight\", \"layer3.2.bn3.running_mean\", \"layer3.2.bn3.running_var\", \"layer3.3.conv1.weight\", \"layer3.3.bn1.bias\", \"layer3.3.bn1.weight\", \"layer3.3.bn1.running_mean\", \"layer3.3.bn1.running_var\", \"layer3.3.conv2.weight\", \"layer3.3.bn2.bias\", \"layer3.3.bn2.weight\", \"layer3.3.bn2.running_mean\", \"layer3.3.bn2.running_var\", \"layer3.3.conv3.weight\", \"layer3.3.bn3.bias\", \"layer3.3.bn3.weight\", \"layer3.3.bn3.running_mean\", \"layer3.3.bn3.running_var\", \"layer3.4.conv1.weight\", \"layer3.4.bn1.bias\", \"layer3.4.bn1.weight\", \"layer3.4.bn1.running_mean\", \"layer3.4.bn1.running_var\", \"layer3.4.conv2.weight\", \"layer3.4.bn2.bias\", \"layer3.4.bn2.weight\", \"layer3.4.bn2.running_mean\", \"layer3.4.bn2.running_var\", \"layer3.4.conv3.weight\", \"layer3.4.bn3.bias\", \"layer3.4.bn3.weight\", \"layer3.4.bn3.running_mean\", \"layer3.4.bn3.running_var\", \"layer3.5.conv1.weight\", \"layer3.5.bn1.bias\", \"layer3.5.bn1.weight\", \"layer3.5.bn1.running_mean\", \"layer3.5.bn1.running_var\", \"layer3.5.conv2.weight\", \"layer3.5.bn2.bias\", \"layer3.5.bn2.weight\", \"layer3.5.bn2.running_mean\", \"layer3.5.bn2.running_var\", \"layer3.5.conv3.weight\", \"layer3.5.bn3.bias\", \"layer3.5.bn3.weight\", \"layer3.5.bn3.running_mean\", \"layer3.5.bn3.running_var\", \"layer4.0.conv1.weight\", \"layer4.0.bn1.bias\", \"layer4.0.bn1.weight\", \"layer4.0.bn1.running_mean\", \"layer4.0.bn1.running_var\", \"layer4.0.conv2.weight\", \"layer4.0.bn2.bias\", \"layer4.0.bn2.weight\", \"layer4.0.bn2.running_mean\", \"layer4.0.bn2.running_var\", \"layer4.0.conv3.weight\", \"layer4.0.bn3.bias\", \"layer4.0.bn3.weight\", \"layer4.0.bn3.running_mean\", \"layer4.0.bn3.running_var\", \"layer4.0.downsample.0.weight\", \"layer4.0.downsample.1.bias\", \"layer4.0.downsample.1.weight\", \"layer4.0.downsample.1.running_mean\", \"layer4.0.downsample.1.running_var\", \"layer4.1.conv1.weight\", \"layer4.1.bn1.bias\", \"layer4.1.bn1.weight\", \"layer4.1.bn1.running_mean\", \"layer4.1.bn1.running_var\", \"layer4.1.conv2.weight\", \"layer4.1.bn2.bias\", \"layer4.1.bn2.weight\", \"layer4.1.bn2.running_mean\", \"layer4.1.bn2.running_var\", \"layer4.1.conv3.weight\", \"layer4.1.bn3.bias\", \"layer4.1.bn3.weight\", \"layer4.1.bn3.running_mean\", \"layer4.1.bn3.running_var\", \"layer4.2.conv1.weight\", \"layer4.2.bn1.bias\", \"layer4.2.bn1.weight\", \"layer4.2.bn1.running_mean\", \"layer4.2.bn1.running_var\", \"layer4.2.conv2.weight\", \"layer4.2.bn2.bias\", \"layer4.2.bn2.weight\", \"layer4.2.bn2.running_mean\", \"layer4.2.bn2.running_var\", \"layer4.2.conv3.weight\", \"layer4.2.bn3.bias\", \"layer4.2.bn3.weight\", \"layer4.2.bn3.running_mean\", \"layer4.2.bn3.running_var\", \"fc.bias\", \"fc.weight\". \n\tUnexpected key(s) in state_dict: \"module.conv1.weight\", \"module.bn1.weight\", \"module.bn1.bias\", \"module.bn1.running_mean\", \"module.bn1.running_var\", \"module.bn1.num_batches_tracked\", \"module.layer1.0.conv1.weight\", \"module.layer1.0.bn1.weight\", \"module.layer1.0.bn1.bias\", \"module.layer1.0.bn1.running_mean\", \"module.layer1.0.bn1.running_var\", \"module.layer1.0.bn1.num_batches_tracked\", \"module.layer1.0.conv2.weight\", \"module.layer1.0.bn2.weight\", \"module.layer1.0.bn2.bias\", \"module.layer1.0.bn2.running_mean\", \"module.layer1.0.bn2.running_var\", \"module.layer1.0.bn2.num_batches_tracked\", \"module.layer1.0.conv3.weight\", \"module.layer1.0.bn3.weight\", \"module.layer1.0.bn3.bias\", \"module.layer1.0.bn3.running_mean\", \"module.layer1.0.bn3.running_var\", \"module.layer1.0.bn3.num_batches_tracked\", \"module.layer1.0.downsample.0.weight\", \"module.layer1.0.downsample.1.weight\", \"module.layer1.0.downsample.1.bias\", \"module.layer1.0.downsample.1.running_mean\", \"module.layer1.0.downsample.1.running_var\", \"module.layer1.0.downsample.1.num_batches_tracked\", \"module.layer1.1.conv1.weight\", \"module.layer1.1.bn1.weight\", \"module.layer1.1.bn1.bias\", \"module.layer1.1.bn1.running_mean\", \"module.layer1.1.bn1.running_var\", \"module.layer1.1.bn1.num_batches_tracked\", \"module.layer1.1.conv2.weight\", \"module.layer1.1.bn2.weight\", \"module.layer1.1.bn2.bias\", \"module.layer1.1.bn2.running_mean\", \"module.layer1.1.bn2.running_var\", \"module.layer1.1.bn2.num_batches_tracked\", \"module.layer1.1.conv3.weight\", \"module.layer1.1.bn3.weight\", \"module.layer1.1.bn3.bias\", \"module.layer1.1.bn3.running_mean\", \"module.layer1.1.bn3.running_var\", \"module.layer1.1.bn3.num_batches_tracked\", \"module.layer1.2.conv1.weight\", \"module.layer1.2.bn1.weight\", \"module.layer1.2.bn1.bias\", \"module.layer1.2.bn1.running_mean\", \"module.layer1.2.bn1.running_var\", \"module.layer1.2.bn1.num_batches_tracked\", \"module.layer1.2.conv2.weight\", \"module.layer1.2.bn2.weight\", \"module.layer1.2.bn2.bias\", \"module.layer1.2.bn2.running_mean\", \"module.layer1.2.bn2.running_var\", \"module.layer1.2.bn2.num_batches_tracked\", \"module.layer1.2.conv3.weight\", \"module.layer1.2.bn3.weight\", \"module.layer1.2.bn3.bias\", \"module.layer1.2.bn3.running_mean\", \"module.layer1.2.bn3.running_var\", \"module.layer1.2.bn3.num_batches_tracked\", \"module.layer2.0.conv1.weight\", \"module.layer2.0.bn1.weight\", \"module.layer2.0.bn1.bias\", \"module.layer2.0.bn1.running_mean\", \"module.layer2.0.bn1.running_var\", \"module.layer2.0.bn1.num_batches_tracked\", \"module.layer2.0.conv2.weight\", \"module.layer2.0.bn2.weight\", \"module.layer2.0.bn2.bias\", \"module.layer2.0.bn2.running_mean\", \"module.layer2.0.bn2.running_var\", \"module.layer2.0.bn2.num_batches_tracked\", \"module.layer2.0.conv3.weight\", \"module.layer2.0.bn3.weight\", \"module.layer2.0.bn3.bias\", \"module.layer2.0.bn3.running_mean\", \"module.layer2.0.bn3.running_var\", \"module.layer2.0.bn3.num_batches_tracked\", \"module.layer2.0.downsample.0.weight\", \"module.layer2.0.downsample.1.weight\", \"module.layer2.0.downsample.1.bias\", \"module.layer2.0.downsample.1.running_mean\", \"module.layer2.0.downsample.1.running_var\", \"module.layer2.0.downsample.1.num_batches_tracked\", \"module.layer2.1.conv1.weight\", \"module.layer2.1.bn1.weight\", \"module.layer2.1.bn1.bias\", \"module.layer2.1.bn1.running_mean\", \"module.layer2.1.bn1.running_var\", \"module.layer2.1.bn1.num_batches_tracked\", \"module.layer2.1.conv2.weight\", \"module.layer2.1.bn2.weight\", \"module.layer2.1.bn2.bias\", \"module.layer2.1.bn2.running_mean\", \"module.layer2.1.bn2.running_var\", \"module.layer2.1.bn2.num_batches_tracked\", \"module.layer2.1.conv3.weight\", \"module.layer2.1.bn3.weight\", \"module.layer2.1.bn3.bias\", \"module.layer2.1.bn3.running_mean\", \"module.layer2.1.bn3.running_var\", \"module.layer2.1.bn3.num_batches_tracked\", \"module.layer2.2.conv1.weight\", \"module.layer2.2.bn1.weight\", \"module.layer2.2.bn1.bias\", \"module.layer2.2.bn1.running_mean\", \"module.layer2.2.bn1.running_var\", \"module.layer2.2.bn1.num_batches_tracked\", \"module.layer2.2.conv2.weight\", \"module.layer2.2.bn2.weight\", \"module.layer2.2.bn2.bias\", \"module.layer2.2.bn2.running_mean\", \"module.layer2.2.bn2.running_var\", \"module.layer2.2.bn2.num_batches_tracked\", \"module.layer2.2.conv3.weight\", \"module.layer2.2.bn3.weight\", \"module.layer2.2.bn3.bias\", \"module.layer2.2.bn3.running_mean\", \"module.layer2.2.bn3.running_var\", \"module.layer2.2.bn3.num_batches_tracked\", \"module.layer2.3.conv1.weight\", \"module.layer2.3.bn1.weight\", \"module.layer2.3.bn1.bias\", \"module.layer2.3.bn1.running_mean\", \"module.layer2.3.bn1.running_var\", \"module.layer2.3.bn1.num_batches_tracked\", \"module.layer2.3.conv2.weight\", \"module.layer2.3.bn2.weight\", \"module.layer2.3.bn2.bias\", \"module.layer2.3.bn2.running_mean\", \"module.layer2.3.bn2.running_var\", \"module.layer2.3.bn2.num_batches_tracked\", \"module.layer2.3.conv3.weight\", \"module.layer2.3.bn3.weight\", \"module.layer2.3.bn3.bias\", \"module.layer2.3.bn3.running_mean\", \"module.layer2.3.bn3.running_var\", \"module.layer2.3.bn3.num_batches_tracked\", \"module.layer3.0.conv1.weight\", \"module.layer3.0.bn1.weight\", \"module.layer3.0.bn1.bias\", \"module.layer3.0.bn1.running_mean\", \"module.layer3.0.bn1.running_var\", \"module.layer3.0.bn1.num_batches_tracked\", \"module.layer3.0.conv2.weight\", \"module.layer3.0.bn2.weight\", \"module.layer3.0.bn2.bias\", \"module.layer3.0.bn2.running_mean\", \"module.layer3.0.bn2.running_var\", \"module.layer3.0.bn2.num_batches_tracked\", \"module.layer3.0.conv3.weight\", \"module.layer3.0.bn3.weight\", \"module.layer3.0.bn3.bias\", \"module.layer3.0.bn3.running_mean\", \"module.layer3.0.bn3.running_var\", \"module.layer3.0.bn3.num_batches_tracked\", \"module.layer3.0.downsample.0.weight\", \"module.layer3.0.downsample.1.weight\", \"module.layer3.0.downsample.1.bias\", \"module.layer3.0.downsample.1.running_mean\", \"module.layer3.0.downsample.1.running_var\", \"module.layer3.0.downsample.1.num_batches_tracked\", \"module.layer3.1.conv1.weight\", \"module.layer3.1.bn1.weight\", \"module.layer3.1.bn1.bias\", \"module.layer3.1.bn1.running_mean\", \"module.layer3.1.bn1.running_var\", \"module.layer3.1.bn1.num_batches_tracked\", \"module.layer3.1.conv2.weight\", \"module.layer3.1.bn2.weight\", \"module.layer3.1.bn2.bias\", \"module.layer3.1.bn2.running_mean\", \"module.layer3.1.bn2.running_var\", \"module.layer3.1.bn2.num_batches_tracked\", \"module.layer3.1.conv3.weight\", \"module.layer3.1.bn3.weight\", \"module.layer3.1.bn3.bias\", \"module.layer3.1.bn3.running_mean\", \"module.layer3.1.bn3.running_var\", \"module.layer3.1.bn3.num_batches_tracked\", \"module.layer3.2.conv1.weight\", \"module.layer3.2.bn1.weight\", \"module.layer3.2.bn1.bias\", \"module.layer3.2.bn1.running_mean\", \"module.layer3.2.bn1.running_var\", \"module.layer3.2.bn1.num_batches_tracked\", \"module.layer3.2.conv2.weight\", \"module.layer3.2.bn2.weight\", \"module.layer3.2.bn2.bias\", \"module.layer3.2.bn2.running_mean\", \"module.layer3.2.bn2.running_var\", \"module.layer3.2.bn2.num_batches_tracked\", \"module.layer3.2.conv3.weight\", \"module.layer3.2.bn3.weight\", \"module.layer3.2.bn3.bias\", \"module.layer3.2.bn3.running_mean\", \"module.layer3.2.bn3.running_var\", \"module.layer3.2.bn3.num_batches_tracked\", \"module.layer3.3.conv1.weight\", \"module.layer3.3.bn1.weight\", \"module.layer3.3.bn1.bias\", \"module.layer3.3.bn1.running_mean\", \"module.layer3.3.bn1.running_var\", \"module.layer3.3.bn1.num_batches_tracked\", \"module.layer3.3.conv2.weight\", \"module.layer3.3.bn2.weight\", \"module.layer3.3.bn2.bias\", \"module.layer3.3.bn2.running_mean\", \"module.layer3.3.bn2.running_var\", \"module.layer3.3.bn2.num_batches_tracked\", \"module.layer3.3.conv3.weight\", \"module.layer3.3.bn3.weight\", \"module.layer3.3.bn3.bias\", \"module.layer3.3.bn3.running_mean\", \"module.layer3.3.bn3.running_var\", \"module.layer3.3.bn3.num_batches_tracked\", \"module.layer3.4.conv1.weight\", \"module.layer3.4.bn1.weight\", \"module.layer3.4.bn1.bias\", \"module.layer3.4.bn1.running_mean\", \"module.layer3.4.bn1.running_var\", \"module.layer3.4.bn1.num_batches_tracked\", \"module.layer3.4.conv2.weight\", \"module.layer3.4.bn2.weight\", \"module.layer3.4.bn2.bias\", \"module.layer3.4.bn2.running_mean\", \"module.layer3.4.bn2.running_var\", \"module.layer3.4.bn2.num_batches_tracked\", \"module.layer3.4.conv3.weight\", \"module.layer3.4.bn3.weight\", \"module.layer3.4.bn3.bias\", \"module.layer3.4.bn3.running_mean\", \"module.layer3.4.bn3.running_var\", \"module.layer3.4.bn3.num_batches_tracked\", \"module.layer3.5.conv1.weight\", \"module.layer3.5.bn1.weight\", \"module.layer3.5.bn1.bias\", \"module.layer3.5.bn1.running_mean\", \"module.layer3.5.bn1.running_var\", \"module.layer3.5.bn1.num_batches_tracked\", \"module.layer3.5.conv2.weight\", \"module.layer3.5.bn2.weight\", \"module.layer3.5.bn2.bias\", \"module.layer3.5.bn2.running_mean\", \"module.layer3.5.bn2.running_var\", \"module.layer3.5.bn2.num_batches_tracked\", \"module.layer3.5.conv3.weight\", \"module.layer3.5.bn3.weight\", \"module.layer3.5.bn3.bias\", \"module.layer3.5.bn3.running_mean\", \"module.layer3.5.bn3.running_var\", \"module.layer3.5.bn3.num_batches_tracked\", \"module.layer4.0.conv1.weight\", \"module.layer4.0.bn1.weight\", \"module.layer4.0.bn1.bias\", \"module.layer4.0.bn1.running_mean\", \"module.layer4.0.bn1.running_var\", \"module.layer4.0.bn1.num_batches_tracked\", \"module.layer4.0.conv2.weight\", \"module.layer4.0.bn2.weight\", \"module.layer4.0.bn2.bias\", \"module.layer4.0.bn2.running_mean\", \"module.layer4.0.bn2.running_var\", \"module.layer4.0.bn2.num_batches_tracked\", \"module.layer4.0.conv3.weight\", \"module.layer4.0.bn3.weight\", \"module.layer4.0.bn3.bias\", \"module.layer4.0.bn3.running_mean\", \"module.layer4.0.bn3.running_var\", \"module.layer4.0.bn3.num_batches_tracked\", \"module.layer4.0.downsample.0.weight\", \"module.layer4.0.downsample.1.weight\", \"module.layer4.0.downsample.1.bias\", \"module.layer4.0.downsample.1.running_mean\", \"module.layer4.0.downsample.1.running_var\", \"module.layer4.0.downsample.1.num_batches_tracked\", \"module.layer4.1.conv1.weight\", \"module.layer4.1.bn1.weight\", \"module.layer4.1.bn1.bias\", \"module.layer4.1.bn1.running_mean\", \"module.layer4.1.bn1.running_var\", \"module.layer4.1.bn1.num_batches_tracked\", \"module.layer4.1.conv2.weight\", \"module.layer4.1.bn2.weight\", \"module.layer4.1.bn2.bias\", \"module.layer4.1.bn2.running_mean\", \"module.layer4.1.bn2.running_var\", \"module.layer4.1.bn2.num_batches_tracked\", \"module.layer4.1.conv3.weight\", \"module.layer4.1.bn3.weight\", \"module.layer4.1.bn3.bias\", \"module.layer4.1.bn3.running_mean\", \"module.layer4.1.bn3.running_var\", \"module.layer4.1.bn3.num_batches_tracked\", \"module.layer4.2.conv1.weight\", \"module.layer4.2.bn1.weight\", \"module.layer4.2.bn1.bias\", \"module.layer4.2.bn1.running_mean\", \"module.layer4.2.bn1.running_var\", \"module.layer4.2.bn1.num_batches_tracked\", \"module.layer4.2.conv2.weight\", \"module.layer4.2.bn2.weight\", \"module.layer4.2.bn2.bias\", \"module.layer4.2.bn2.running_mean\", \"module.layer4.2.bn2.running_var\", \"module.layer4.2.bn2.num_batches_tracked\", \"module.layer4.2.conv3.weight\", \"module.layer4.2.bn3.weight\", \"module.layer4.2.bn3.bias\", \"module.layer4.2.bn3.running_mean\", \"module.layer4.2.bn3.running_var\", \"module.layer4.2.bn3.num_batches_tracked\", \"module.fc.weight\", \"module.fc.bias\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-b3869b7f0e83>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0moptimizer_ft\u001b[0m     \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_ft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mexp_lr_scheduler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr_scheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStepLR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer_ft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mload_checkpoint_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../python/checkpoints/vehicle_distance/model_19.tar'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_ft\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mnum_ftrs\u001b[0m         \u001b[0;34m=\u001b[0m \u001b[0mmodel_ft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mmodel_ft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m      \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_ftrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-372c09a891d5>\u001b[0m in \u001b[0;36mload_checkpoint_weights\u001b[0;34m(checkpoint, model)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"checkpoint name : \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0m_model_state_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_optimizer_state_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_model_state_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mresume_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/data1/duvindu/sw/anaconda3/envs/coiltraine/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m    843\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    844\u001b[0m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0;32m--> 845\u001b[0;31m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0m\u001b[1;32m    846\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    847\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for ResNet:\n\tMissing key(s) in state_dict: \"conv1.weight\", \"bn1.bias\", \"bn1.weight\", \"bn1.running_mean\", \"bn1.running_var\", \"layer1.0.conv1.weight\", \"layer1.0.bn1.bias\", \"layer1.0.bn1.weight\", \"layer1.0.bn1.running_mean\", \"layer1.0.bn1.running_var\", \"layer1.0.conv2.weight\", \"layer1.0.bn2.bias\", \"layer1.0.bn2.weight\", \"layer1.0.bn2.running_mean\", \"layer1.0.bn2.running_var\", \"layer1.0.conv3.weight\", \"layer1.0.bn3.bias\", \"layer1.0.bn3.weight\", \"layer1.0.bn3.running_mean\", \"layer1.0.bn3.running_var\", \"layer1.0.downsample.0.weight\", \"layer1.0.downsample.1.bias\", \"layer1.0.downsample.1.weight\", \"layer1.0.downsample.1.running_mean\", \"layer1.0.downsample.1.running_var\", \"layer1.1.conv1.weight\", \"layer1.1.bn1.bias\", \"layer1.1.bn1.weight\", \"layer1.1.bn1.running_mean\", \"layer1.1.bn1.running_var\", \"layer1.1.conv2.weight\", \"layer1.1.bn2.bias\", \"layer1.1.bn2.weight\", \"layer1.1.bn2.running_mean\", \"layer1.1.bn2.running_var\", \"layer1.1.conv3.weight\", \"layer1.1.bn3.bias\", \"layer1.1.bn3.weight\", \"layer1.1.bn3.running_mean\", \"layer1.1.bn3.running_var\", \"layer1.2.conv1.weight\", \"layer1.2.bn1.bias\", \"layer1.2.bn1.weight\", \"layer1.2.bn1.running_mean\", \"layer1.2.bn1.running_var\", \"layer1.2.conv2.weight\", \"layer1.2.bn2.bias\", \"layer1.2.bn2.weight\", \"layer1.2.bn2.running_mean\", \"layer1.2.bn2.running_var\", \"layer1.2.conv3.weight\", \"layer1.2.bn3.bias\", \"layer1.2.bn3.weight\", \"layer1.2.bn3.running_mean\", \"layer1.2.bn3.running_var\", \"layer2.0.conv1.weight\", \"layer2.0.bn1.bias\", \"layer2.0.bn1.weight\", \"layer2.0.bn1.running_mean\", \"layer2.0.bn1.running_var\", \"layer2.0.conv2.weight\", \"layer2.0.bn2.bias\", \"layer2.0.bn2.weight\", \"layer2.0.bn2.running_mean\", \"layer2.0.bn2.running_var\", \"layer2.0.conv3.weight\", \"layer2.0.bn3.bias\", \"layer2.0.bn3.weight\", \"layer2.0.bn3.running_mean\", \"layer2.0.bn3.running_var\", \"layer2.0.downsample.0.weight\", \"layer2.0.downsample.1.bias\", \"layer2.0.downsample.1.weight\", \"layer2.0.downsample.1.running_mean\", \"layer2.0.downsample.1.running_var\", \"layer2.1.conv1.weight\", \"layer2.1.bn1.bias\", \"layer2.1.bn1.weight\", \"layer2.1.bn1.running_mean\", \"layer2.1.bn1.running_var\", \"layer2.1.conv2.weight\", \"layer2.1.bn2.bias\", \"layer2.1.bn2.weight\", \"layer2.1.bn2.running_mean\", \"layer2.1.bn2.running_var\", \"layer2.1.conv3.weight\", \"layer2.1.bn3.bias\", \"layer2.1.bn3.weight\", \"layer2.1.bn3.running_mean\", \"layer2.1.bn3.running_var\", \"layer2.2.conv1.weight\", \"layer2.2.bn1.bias\", \"layer2.2.bn1.weight\", \"layer2.2.bn1.running_mean\", \"layer2.2.bn1.running_var\", \"layer2.2.conv2.weight\", \"layer2.2.bn2.bias\", \"layer2.2.bn2.weight\", \"layer2.2.bn2.running_mean\", \"layer2.2.bn2.running_var\", \"layer2.2.conv3.weight\", \"layer2.2.bn3.bias\", \"layer2.2.bn3.weight\", \"layer2.2.bn3.running_mean\", \"layer2.2.bn3.running_var\", \"layer2.3.conv1.weight\", \"layer2.3.bn1.bias\", \"layer2.3.bn1.weight\", \"layer2.3.bn1.running_mean\", \"layer2.3.bn1.running_var\", \"layer2.3.conv2.weight\", \"layer2.3.bn2.bias\", \"layer2.3.bn2.weight\", \"layer2.3.bn2.running_mean\", \"layer2.3.bn2.running_var\", \"layer2.3.conv3.weight\", \"layer2.3.bn3.bias\", \"layer2.3.bn3.weight\", \"layer2.3.bn3.running_mean\", \"layer2.3.bn3.running_var\", \"layer3.0.conv1.weight\", \"layer3.0.bn1.bias\", \"layer3.0.bn1.weight\", \"layer3.0.bn1.running_mean\", \"layer3.0.bn1.running_var\", \"layer3.0.conv2.weight\", \"layer3.0.bn2.bias\", \"layer3.0.bn2.weight\", \"layer3.0.bn2.running_mean\", \"layer3.0.bn2.running_var\", \"layer3.0.conv3.weight\", \"layer3.0.bn3.bias\", \"layer3.0.bn3.weight\", \"layer3.0.bn3.running_mean\", \"layer3.0.bn3.running_var\", \"layer3.0.downsample.0.weight\", \"layer3.0.downsample.1.bias\", \"layer3.0.downsample.1.weight\", \"layer3.0.downsample.1.running_mean\", \"layer3.0.downsample.1.running_var\", \"layer3.1.conv1.weight\", \"layer3.1.bn1.bias\", \"layer3.1.bn1.weight\", \"layer3.1.bn1.running_mean\", \"layer3.1.bn1.running_var\", \"layer3.1.conv2.weight\", \"layer3.1.bn2.bias\", \"layer3.1.bn2.weight\", \"layer3.1.bn2.running_mean\", \"layer3.1.bn2.running_var\", \"layer3.1.conv3.weight\", \"layer3.1.bn3.bias\", \"layer3.1.bn3.weight\", \"layer3.1.bn3.running_mean\", \"layer3.1.bn3.running_var\", \"layer3.2.conv1.weight\", \"layer3.2.bn1.bias\", \"layer3.2.bn1.weight\", \"layer3.2.bn1.running_mean\", \"layer3.2.bn1.running_var\", \"layer3.2.conv2.weight\", \"layer3.2.bn2.bias\", \"layer3.2.bn2.weight\", \"layer3.2.bn2.running_mean\", \"layer3.2.bn2.running_var\", \"layer3.2.conv3.weight\", \"layer3.2.bn3.bias\", \"layer3.2.bn3.weight\", \"layer3.2.bn3.running_mean\", \"layer3.2.bn3.running_var\", \"layer3.3.conv1.weight\", \"layer3.3.bn1.bias\", \"layer3.3.bn1.weight\", \"layer3.3.bn1.running_mean\", \"layer3.3.bn1.running_var\", \"layer3.3.conv2.weight\", \"layer3.3.bn2.bias\", \"layer3.3.bn2.weight\", \"layer3.3.bn2.running_mean\", \"layer3.3.bn2.running_var\", \"layer3.3.conv3.weight\", \"layer3.3.bn3.bias\", \"layer3.3.bn3.weight\", \"layer3.3.bn3.running_mean\", \"layer3.3.bn3.running_var\", \"layer3.4.conv1.weight\", \"layer3.4.bn1.bias\", \"layer3.4.bn1.weight\", \"layer3.4.bn1.running_mean\", \"layer3.4.bn1.running_var\", \"layer3.4.conv2.weight\", \"layer3.4.bn2.bias\", \"layer3.4.bn2.weight\", \"layer3.4.bn2.running_mean\", \"layer3.4.bn2.running_var\", \"layer3.4.conv3.weight\", \"layer3.4.bn3.bias\", \"layer3.4.bn3.weight\", \"layer3.4.bn3.running_mean\", \"layer3.4.bn3.running_var\", \"layer3.5.conv1.weight\", \"layer3.5.bn1.bias\", \"layer3.5.bn1.weight\", \"layer3.5.bn1.running_mean\", \"layer3.5.bn1.running_var\", \"layer3.5.conv2.weight\", \"layer3.5.bn2.bias\", \"layer3.5.bn2.weight\", \"layer3.5.bn2.running_mean\", \"layer3.5.bn2.running_var\", \"layer3.5.conv3.weight\", \"layer3.5.bn3.bias\", \"layer3.5.bn3.weight\", \"layer3.5.bn3.running_mean\", \"layer3.5.bn3.running_var\", \"layer4.0.conv1.weight\", \"layer4.0.bn1.bias\", \"layer4.0.bn1.weight\", \"layer4.0.bn1.running_mean\", \"layer4.0.bn1.running_var\", \"layer4.0.conv2.weight\", \"layer4.0.bn2.bias\", \"layer4.0.bn2.weight\", \"layer4.0.bn2.running_mean\", \"layer4.0.bn2.running_var\", \"layer4.0.conv3.weight\", \"layer4.0.bn3.bias\", \"layer4.0.bn3.weight\", \"layer4.0.bn3.running_mean\", \"layer4.0.bn3.running_var\", \"layer4.0.downsample.0.weight\", \"layer4.0.downsample.1.bias\", \"layer4.0.downsample.1.weight\", \"layer4.0.downsample.1.running_mean\", \"layer4.0.downsample.1.running_var\", \"layer4.1.conv1.weight\", \"layer4.1.bn1.bias\", \"layer4.1.bn1.weight\", \"layer4.1.bn1.running_mean\", \"layer4.1.bn1.running_var\", \"layer4.1.conv2.weight\", \"layer4.1.bn2.bias\", \"layer4.1.bn2.weight\", \"layer4.1.bn2.running_mean\", \"layer4.1.bn2.running_var\", \"layer4.1.conv3.weight\", \"layer4.1.bn3.bias\", \"layer4.1.bn3.weight\", \"layer4.1.bn3.running_mean\", \"layer4.1.bn3.running_var\", \"layer4.2.conv1.weight\", \"layer4.2.bn1.bias\", \"layer4.2.bn1.weight\", \"layer4.2.bn1.running_mean\", \"layer4.2.bn1.running_var\", \"layer4.2.conv2.weight\", \"layer4.2.bn2.bias\", \"layer4.2.bn2.weight\", \"layer4.2.bn2.running_mean\", \"layer4.2.bn2.running_var\", \"layer4.2.conv3.weight\", \"layer4.2.bn3.bias\", \"layer4.2.bn3.weight\", \"layer4.2.bn3.running_mean\", \"layer4.2.bn3.running_var\", \"fc.bias\", \"fc.weight\". \n\tUnexpected key(s) in state_dict: \"module.conv1.weight\", \"module.bn1.weight\", \"module.bn1.bias\", \"module.bn1.running_mean\", \"module.bn1.running_var\", \"module.bn1.num_batches_tracked\", \"module.layer1.0.conv1.weight\", \"module.layer1.0.bn1.weight\", \"module.layer1.0.bn1.bias\", \"module.layer1.0.bn1.running_mean\", \"module.layer1.0.bn1.running_var\", \"module.layer1.0.bn1.num_batches_tracked\", \"module.layer1.0.conv2.weight\", \"module.layer1.0.bn2.weight\", \"module.layer1.0.bn2.bias\", \"module.layer1.0.bn2.running_mean\", \"module.layer1.0.bn2.running_var\", \"module.layer1.0.bn2.num_batches_tracked\", \"module.layer1.0.conv3.weight\", \"module.layer1.0.bn3.weight\", \"module.layer1.0.bn3.bias\", \"module.layer1.0.bn3.running_mean\", \"module.layer1.0.bn3.running_var\", \"module.layer1.0.bn3.num_batches_tracked\", \"module.layer1.0.downsample.0.weight\", \"module.layer1.0.downsample.1.weight\", \"module.layer1.0.downsample.1.bias\", \"module.layer1.0.downsample.1.running_mean\", \"module.layer1.0.downsample.1.running_var\", \"module.layer1.0.downsample.1.num_batches_tracked\", \"module.layer1.1.conv1.weight\", \"module.layer1.1.bn1.weight\", \"module.layer1.1.bn1.bias\", \"module.layer1.1.bn1.running_mean\", \"module.layer1.1.bn1.running_var\", \"module.layer1.1.bn1.num_batches_tracked\", \"module.layer1.1.conv2.weight\", \"module.layer1.1.bn2.weight\", \"module.layer1.1.bn2.bias\", \"module.layer1.1.bn2.running_mean\", \"module.layer1.1.bn2.running_var\", \"module.layer1.1.bn2.num_batches_tracked\", \"module.layer1.1.conv3.weight\", \"module.layer1.1.bn3.weight\", \"module.layer1.1.bn3.bias\", \"module.layer1.1.bn3.running_mean\", \"module.layer1.1.bn3.running_var\", \"module.layer1.1.bn3.num_batches_tracked\", \"module.layer1.2.conv1.weight\", \"module.layer1.2.bn1.weight\", \"module.layer1.2.bn1.bias\", \"module.layer1.2.bn1.running_mean\", \"module.layer1.2.bn1.running_var\", \"module.layer1.2.bn1.num_batches_tracked\", \"module.layer1.2.conv2.weight\", \"module.layer1.2.bn2.weight\", \"module.layer1.2.bn2.bias\", \"module.layer1.2.bn2.running_mean\", \"module.layer1.2.bn2.running_var\", \"module.layer1.2.bn2.num_batches_tracked\", \"module.layer1.2.conv3.weight\", \"module.layer1.2.bn3.weight\", \"module.layer1.2.bn3.bias\", \"module.layer1.2.bn3.running_mean\", \"module.layer1.2.bn3.running_var\", \"module.layer1.2.bn3.num_batches_tracked\", \"module.layer2.0.conv1.weight\", \"module.layer2.0.bn1.weight\", \"module.layer2.0.bn1.bias\", \"module.layer2.0.bn1.running_mean\", \"module.layer2.0.bn1.running_var\", \"module.layer2.0.bn1.num_batches_tracked\", \"module.layer2.0.conv2.weight\", \"module.layer2.0.bn2.weight\", \"module.layer2.0.bn2.bias\", \"module.layer2.0.bn2.running_mean\", \"module.layer2.0.bn2.running_var\", \"module.layer2.0.bn2.num_batches_tracked\", \"module.layer2.0.conv3.weight\", \"module.layer2.0.bn3.weight\", \"module.layer2.0.bn3.bias\", \"module.layer2.0.bn3.running_mean\", \"module.layer2.0.bn3.running_var\", \"module.layer2.0.bn3.num_batches_tracked\", \"module.layer2.0.downsample.0.weight\", \"module.layer2.0.downsample.1.weight\", \"module.layer2.0.downsample.1.bias\", \"module.layer2.0.downsample.1.running_mean\", \"module.layer2.0.downsample.1.running_var\", \"module.layer2.0.downsample.1.num_batches_tracked\", \"module.layer2.1.conv1.weight\", \"module.layer2.1.bn1.weight\", \"module.layer2.1.bn1.bias\", \"module.layer2.1.bn1.running_mean\", \"module.layer2.1.bn1.running_var\", \"module.layer2.1.bn1.num_batches_tracked\", \"module.layer2.1.conv2.weight\", \"module.layer2.1.bn2.weight\", \"module.layer2.1.bn2.bias\", \"module.layer2.1.bn2.running_mean\", \"module.layer2.1.bn2.running_var\", \"module.layer2.1.bn2.num_batches_tracked\", \"module.layer2.1.conv3.weight\", \"module.layer2.1.bn3.weight\", \"module.layer2.1.bn3.bias\", \"module.layer2.1.bn3.running_mean\", \"module.layer2.1.bn3.running_var\", \"module.layer2.1.bn3.num_batches_tracked\", \"module.layer2.2.conv1.weight\", \"module.layer2.2.bn1.weight\", \"module.layer2.2.bn1.bias\", \"module.layer2.2.bn1.running_mean\", \"module.layer2.2.bn1.running_var\", \"module.layer2.2.bn1.num_batches_tracked\", \"module.layer2.2.conv2.weight\", \"module.layer2.2.bn2.weight\", \"module.layer2.2.bn2.bias\", \"module.layer2.2.bn2.running_mean\", \"module.layer2.2.bn2.running_var\", \"module.layer2.2.bn2.num_batches_tracked\", \"module.layer2.2.conv3.weight\", \"module.layer2.2.bn3.weight\", \"module.layer2.2.bn3.bias\", \"module.layer2.2.bn3.running_mean\", \"module.layer2.2.bn3.running_var\", \"module.layer2.2.bn3.num_batches_tracked\", \"module.layer2.3.conv1.weight\", \"module.layer2.3.bn1.weight\", \"module.layer2.3.bn1.bias\", \"module.layer2.3.bn1.running_mean\", \"module.layer2.3.bn1.running_var\", \"module.layer2.3.bn1.num_batches_tracked\", \"module.layer2.3.conv2.weight\", \"module.layer2.3.bn2.weight\", \"module.layer2.3.bn2.bias\", \"module.layer2.3.bn2.running_mean\", \"module.layer2.3.bn2.running_var\", \"module.layer2.3.bn2.num_batches_tracked\", \"module.layer2.3.conv3.weight\", \"module.layer2.3.bn3.weight\", \"module.layer2.3.bn3.bias\", \"module.layer2.3.bn3.running_mean\", \"module.layer2.3.bn3.running_var\", \"module.layer2.3.bn3.num_batches_tracked\", \"module.layer3.0.conv1.weight\", \"module.layer3.0.bn1.weight\", \"module.layer3.0.bn1.bias\", \"module.layer3.0.bn1.running_mean\", \"module.layer3.0.bn1.running_var\", \"module.layer3.0.bn1.num_batches_tracked\", \"module.layer3.0.conv2.weight\", \"module.layer3.0.bn2.weight\", \"module.layer3.0.bn2.bias\", \"module.layer3.0.bn2.running_mean\", \"module.layer3.0.bn2.running_var\", \"module.layer3.0.bn2.num_batches_tracked\", \"module.layer3.0.conv3.weight\", \"module.layer3.0.bn3.weight\", \"module.layer3.0.bn3.bias\", \"module.layer3.0.bn3.running_mean\", \"module.layer3.0.bn3.running_var\", \"module.layer3.0.bn3.num_batches_tracked\", \"module.layer3.0.downsample.0.weight\", \"module.layer3.0.downsample.1.weight\", \"module.layer3.0.downsample.1.bias\", \"module.layer3.0.downsample.1.running_mean\", \"module.layer3.0.downsample.1.running_var\", \"module.layer3.0.downsample.1.num_batches_tracked\", \"module.layer3.1.conv1.weight\", \"module.layer3.1.bn1.weight\", \"module.layer3.1.bn1.bias\", \"module.layer3.1.bn1.running_mean\", \"module.layer3.1.bn1.running_var\", \"module.layer3.1.bn1.num_batches_tracked\", \"module.layer3.1.conv2.weight\", \"module.layer3.1.bn2.weight\", \"module.layer3.1.bn2.bias\", \"module.layer3.1.bn2.running_mean\", \"module.layer3.1.bn2.running_var\", \"module.layer3.1.bn2.num_batches_tracked\", \"module.layer3.1.conv3.weight\", \"module.layer3.1.bn3.weight\", \"module.layer3.1.bn3.bias\", \"module.layer3.1.bn3.running_mean\", \"module.layer3.1.bn3.running_var\", \"module.layer3.1.bn3.num_batches_tracked\", \"module.layer3.2.conv1.weight\", \"module.layer3.2.bn1.weight\", \"module.layer3.2.bn1.bias\", \"module.layer3.2.bn1.running_mean\", \"module.layer3.2.bn1.running_var\", \"module.layer3.2.bn1.num_batches_tracked\", \"module.layer3.2.conv2.weight\", \"module.layer3.2.bn2.weight\", \"module.layer3.2.bn2.bias\", \"module.layer3.2.bn2.running_mean\", \"module.layer3.2.bn2.running_var\", \"module.layer3.2.bn2.num_batches_tracked\", \"module.layer3.2.conv3.weight\", \"module.layer3.2.bn3.weight\", \"module.layer3.2.bn3.bias\", \"module.layer3.2.bn3.running_mean\", \"module.layer3.2.bn3.running_var\", \"module.layer3.2.bn3.num_batches_tracked\", \"module.layer3.3.conv1.weight\", \"module.layer3.3.bn1.weight\", \"module.layer3.3.bn1.bias\", \"module.layer3.3.bn1.running_mean\", \"module.layer3.3.bn1.running_var\", \"module.layer3.3.bn1.num_batches_tracked\", \"module.layer3.3.conv2.weight\", \"module.layer3.3.bn2.weight\", \"module.layer3.3.bn2.bias\", \"module.layer3.3.bn2.running_mean\", \"module.layer3.3.bn2.running_var\", \"module.layer3.3.bn2.num_batches_tracked\", \"module.layer3.3.conv3.weight\", \"module.layer3.3.bn3.weight\", \"module.layer3.3.bn3.bias\", \"module.layer3.3.bn3.running_mean\", \"module.layer3.3.bn3.running_var\", \"module.layer3.3.bn3.num_batches_tracked\", \"module.layer3.4.conv1.weight\", \"module.layer3.4.bn1.weight\", \"module.layer3.4.bn1.bias\", \"module.layer3.4.bn1.running_mean\", \"module.layer3.4.bn1.running_var\", \"module.layer3.4.bn1.num_batches_tracked\", \"module.layer3.4.conv2.weight\", \"module.layer3.4.bn2.weight\", \"module.layer3.4.bn2.bias\", \"module.layer3.4.bn2.running_mean\", \"module.layer3.4.bn2.running_var\", \"module.layer3.4.bn2.num_batches_tracked\", \"module.layer3.4.conv3.weight\", \"module.layer3.4.bn3.weight\", \"module.layer3.4.bn3.bias\", \"module.layer3.4.bn3.running_mean\", \"module.layer3.4.bn3.running_var\", \"module.layer3.4.bn3.num_batches_tracked\", \"module.layer3.5.conv1.weight\", \"module.layer3.5.bn1.weight\", \"module.layer3.5.bn1.bias\", \"module.layer3.5.bn1.running_mean\", \"module.layer3.5.bn1.running_var\", \"module.layer3.5.bn1.num_batches_tracked\", \"module.layer3.5.conv2.weight\", \"module.layer3.5.bn2.weight\", \"module.layer3.5.bn2.bias\", \"module.layer3.5.bn2.running_mean\", \"module.layer3.5.bn2.running_var\", \"module.layer3.5.bn2.num_batches_tracked\", \"module.layer3.5.conv3.weight\", \"module.layer3.5.bn3.weight\", \"module.layer3.5.bn3.bias\", \"module.layer3.5.bn3.running_mean\", \"module.layer3.5.bn3.running_var\", \"module.layer3.5.bn3.num_batches_tracked\", \"module.layer4.0.conv1.weight\", \"module.layer4.0.bn1.weight\", \"module.layer4.0.bn1.bias\", \"module.layer4.0.bn1.running_mean\", \"module.layer4.0.bn1.running_var\", \"module.layer4.0.bn1.num_batches_tracked\", \"module.layer4.0.conv2.weight\", \"module.layer4.0.bn2.weight\", \"module.layer4.0.bn2.bias\", \"module.layer4.0.bn2.running_mean\", \"module.layer4.0.bn2.running_var\", \"module.layer4.0.bn2.num_batches_tracked\", \"module.layer4.0.conv3.weight\", \"module.layer4.0.bn3.weight\", \"module.layer4.0.bn3.bias\", \"module.layer4.0.bn3.running_mean\", \"module.layer4.0.bn3.running_var\", \"module.layer4.0.bn3.num_batches_tracked\", \"module.layer4.0.downsample.0.weight\", \"module.layer4.0.downsample.1.weight\", \"module.layer4.0.downsample.1.bias\", \"module.layer4.0.downsample.1.running_mean\", \"module.layer4.0.downsample.1.running_var\", \"module.layer4.0.downsample.1.num_batches_tracked\", \"module.layer4.1.conv1.weight\", \"module.layer4.1.bn1.weight\", \"module.layer4.1.bn1.bias\", \"module.layer4.1.bn1.running_mean\", \"module.layer4.1.bn1.running_var\", \"module.layer4.1.bn1.num_batches_tracked\", \"module.layer4.1.conv2.weight\", \"module.layer4.1.bn2.weight\", \"module.layer4.1.bn2.bias\", \"module.layer4.1.bn2.running_mean\", \"module.layer4.1.bn2.running_var\", \"module.layer4.1.bn2.num_batches_tracked\", \"module.layer4.1.conv3.weight\", \"module.layer4.1.bn3.weight\", \"module.layer4.1.bn3.bias\", \"module.layer4.1.bn3.running_mean\", \"module.layer4.1.bn3.running_var\", \"module.layer4.1.bn3.num_batches_tracked\", \"module.layer4.2.conv1.weight\", \"module.layer4.2.bn1.weight\", \"module.layer4.2.bn1.bias\", \"module.layer4.2.bn1.running_mean\", \"module.layer4.2.bn1.running_var\", \"module.layer4.2.bn1.num_batches_tracked\", \"module.layer4.2.conv2.weight\", \"module.layer4.2.bn2.weight\", \"module.layer4.2.bn2.bias\", \"module.layer4.2.bn2.running_mean\", \"module.layer4.2.bn2.running_var\", \"module.layer4.2.bn2.num_batches_tracked\", \"module.layer4.2.conv3.weight\", \"module.layer4.2.bn3.weight\", \"module.layer4.2.bn3.bias\", \"module.layer4.2.bn3.running_mean\", \"module.layer4.2.bn3.running_var\", \"module.layer4.2.bn3.num_batches_tracked\", \"module.fc.weight\", \"module.fc.bias\". "
     ]
    }
   ],
   "source": [
    "#model definitions\n",
    "model_ft         = models.resnet50(pretrained=True)\n",
    "criterion        = nn.MSELoss()\n",
    "optimizer_ft     = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
    "load_checkpoint_weights('../python/checkpoints/vehicle_distance/model_19.tar', model_ft)\n",
    "num_ftrs         = model_ft.fc.in_features\n",
    "model_ft.fc      = nn.Linear(num_ftrs, 3)\n",
    "model_ft         = nn.DataParallel(model_ft)\n",
    "model_ft         = model_ft.to(device)\n",
    "print(\"copying model to device....\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting training...\n",
      "Epoch 0/49\n",
      "----------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-f20f607dbaa1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#if(args.retrain == True) :\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m  \u001b[0;31m#   resume_model(args.checkpoint, model_ft, optimizer_ft)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_ft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_ft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexp_lr_scheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-11-b7a2467d15c4>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, dataloaders, dataset_sizes, criterion, optimizer, scheduler, num_epochs)\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0;31m# Iterate over data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0;31m#for inputs, labels in dataloaders[phase]:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mphase\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m             \u001b[0;31m#for i, data in tqdm(dataloaders[phase]) :\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m                 \u001b[0minputs_old\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/data1/duvindu/sw/anaconda3/envs/coiltraine/lib/python3.5/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    802\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    803\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 804\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    805\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/data1/duvindu/sw/anaconda3/envs/coiltraine/lib/python3.5/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    759\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 761\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    762\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/data1/duvindu/sw/anaconda3/envs/coiltraine/lib/python3.5/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    722\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    723\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 724\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    725\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/data1/duvindu/sw/anaconda3/envs/coiltraine/lib/python3.5/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    171\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m             \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/data1/duvindu/sw/anaconda3/envs/coiltraine/lib/python3.5/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-4:\n",
      "Traceback (most recent call last):\n",
      "  File \"/media/data1/duvindu/sw/anaconda3/envs/coiltraine/lib/python3.5/threading.py\", line 914, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/media/data1/duvindu/sw/anaconda3/envs/coiltraine/lib/python3.5/threading.py\", line 862, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/media/data1/duvindu/sw/anaconda3/envs/coiltraine/lib/python3.5/site-packages/torch/utils/data/_utils/pin_memory.py\", line 21, in _pin_memory_loop\n",
      "    r = in_queue.get(timeout=MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/media/data1/duvindu/sw/anaconda3/envs/coiltraine/lib/python3.5/multiprocessing/queues.py\", line 113, in get\n",
      "    return ForkingPickler.loads(res)\n",
      "  File \"/media/data1/duvindu/sw/anaconda3/envs/coiltraine/lib/python3.5/site-packages/torch/multiprocessing/reductions.py\", line 284, in rebuild_storage_fd\n",
      "    fd = df.detach()\n",
      "  File \"/media/data1/duvindu/sw/anaconda3/envs/coiltraine/lib/python3.5/multiprocessing/resource_sharer.py\", line 57, in detach\n",
      "    with _resource_sharer.get_connection(self._id) as conn:\n",
      "  File \"/media/data1/duvindu/sw/anaconda3/envs/coiltraine/lib/python3.5/multiprocessing/resource_sharer.py\", line 87, in get_connection\n",
      "    c = Client(address, authkey=process.current_process().authkey)\n",
      "  File \"/media/data1/duvindu/sw/anaconda3/envs/coiltraine/lib/python3.5/multiprocessing/connection.py\", line 487, in Client\n",
      "    c = SocketClient(address)\n",
      "  File \"/media/data1/duvindu/sw/anaconda3/envs/coiltraine/lib/python3.5/multiprocessing/connection.py\", line 614, in SocketClient\n",
      "    s.connect(address)\n",
      "FileNotFoundError: [Errno 2] No such file or directory\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#train model\n",
    "print(\"starting training...\")\n",
    "#if(args.retrain == True) : \n",
    " #   resume_model(args.checkpoint, model_ft, optimizer_ft)\n",
    "train_model(model_ft, dataloaders, dataset_sizes, criterion, optimizer_ft, exp_lr_scheduler, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "data_loader.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
